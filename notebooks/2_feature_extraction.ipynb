{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Feature extraction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b80ec731d16a5705"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Libs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f3b196b8abad268"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from mbp.preprocessing.loader import Loader\n",
    "from mbp.feature_extraction.open_face import OpenFaceFeatureExtractor\n",
    "from mbp.feature_extraction.open_smile import OpenSmileFeatureExtractor\n",
    "\n",
    "from scripts.data_objects import SIT_PARTS, SITVersion\n",
    "from scripts.datasets import sit_datasets\n",
    "from scripts.utils import extract_id_clip"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dc77514cd062cbf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ffc9362b311fbd02"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## OpenFace"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23c9fc67c8b54524"
  },
  {
   "cell_type": "code",
   "source": [
    "def extract_open_face_features(dataset):\n",
    "    print(f'Extracting dataset from: {dataset.corrected}...')\n",
    "    loader = Loader(dataset.corrected, dataset.video_extension)\n",
    "    data = loader.load()\n",
    "    output_path = Path(dataset.processed) / 'open_face_features'\n",
    "    output_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    extractor = OpenFaceFeatureExtractor(output_path,\n",
    "                                         correct_timespan=True,\n",
    "                                         aus=True,\n",
    "                                         au_static=True,\n",
    "                                         pose=True,\n",
    "                                         tracked=False,\n",
    "                                         gaze=True)\n",
    "\n",
    "    for video_path in tqdm(data):\n",
    "        extractor.run(video_path)"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for dataset in sit_datasets.values():\n",
    "    extract_open_face_features(dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ccf83423c721ff0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## OpenSmile"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edc5a5bc138ece13"
  },
  {
   "cell_type": "code",
   "source": [
    "def extract_features_for_participant(data: pd.DataFrame,\n",
    "                                     feature_extractor,\n",
    "                                     dataset_version: type[SITVersion],\n",
    "                                     participant_id: str) -> pd.DataFrame:\n",
    "    all_features = []\n",
    "\n",
    "    participant_videos = (data[data['id'] == participant_id]\n",
    "                          .sort_values(by='path')\n",
    "                          .iterrows())\n",
    "\n",
    "    participant_videos = participant_videos if (\n",
    "            dataset_version == SITVersion.ONLINE\n",
    "    ) else [list(participant_videos)[-1]]  # analyze only last video\n",
    "\n",
    "    for index, row in participant_videos:\n",
    "        video_clip = row['clip'] if (\n",
    "                dataset_version == SITVersion.ONLINE\n",
    "        ) else '2'  # if desktop version, only second part is analysed\n",
    "        parts = SIT_PARTS[dataset_version][video_clip]\n",
    "\n",
    "        for part in parts:\n",
    "            if part.speaker == 'actress':\n",
    "                # Skip processing when the actress is speaking\n",
    "                continue\n",
    "            filepath = feature_extractor.run(row['path'],\n",
    "                                             start=part.start,\n",
    "                                             end=part.end)\n",
    "            features = pd.read_csv(filepath)\n",
    "            filepath.unlink()\n",
    "            features['part'] = part.name\n",
    "            features['id'] = participant_id\n",
    "            all_features.append(features)\n",
    "\n",
    "    return pd.concat(all_features).reset_index()\n",
    "\n",
    "\n",
    "def extract_features(data, output_path, dataset):\n",
    "    feature_extractor = OpenSmileFeatureExtractor(output_path)\n",
    "\n",
    "    data[['id', 'clip']] = data.T.apply(lambda row:\n",
    "                                        extract_id_clip(row['path'].stem)).T\n",
    "\n",
    "    for participant_id in tqdm(data['id'].unique()):\n",
    "        if participant_id in dataset.blacklist:\n",
    "            continue\n",
    "        output_filepath = output_path / f'{participant_id}.csv'\n",
    "        if output_filepath.is_file():\n",
    "            continue\n",
    "        try:\n",
    "            features = extract_features_for_participant(data,\n",
    "                                                        feature_extractor,\n",
    "                                                        dataset.SIT_version,\n",
    "                                                        participant_id)\n",
    "            features.to_csv(output_filepath, index=False)\n",
    "        except Exception as e:\n",
    "            print(f'Error processing video: {participant_id}')\n",
    "            print(f'Error message: {e}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c77318c882d0aff5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for dataset in sit_datasets.values():\n",
    "    print(f'Extracting features for: {dataset.corrected}...')\n",
    "    loader = Loader(dataset.corrected, dataset.video_extension)\n",
    "    data = loader.load()\n",
    "    data = pd.DataFrame(data, columns=['path'])\n",
    "\n",
    "    output_path = Path(dataset.processed) / 'open_smile_features'\n",
    "    output_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    extract_features(data, output_path, dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32a1101903545fd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e40f3edeb8ad21e3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
